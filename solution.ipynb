{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7644def4",
   "metadata": {},
   "source": [
    "1. Клонирование репозитория и переход в рабочую директорию проекта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5199339b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'sprint2' already exists and is not an empty directory.\n",
      "/home/ubuntu/sprint2\n",
      "configs  requirements.txt  solution.ipynb  src\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.venv/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/chirkoov/sprint2.git\n",
    "%cd sprint2\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0caab43a",
   "metadata": {},
   "source": [
    "2. Установка зависимостей\n",
    "\n",
    "команду !sed -i '/pywin32/d' requirements.txt нужно закомментировать, если проект выполняется на windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f18c483f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed -i '/pywin32/d' requirements.txt\n",
    "!pip -q install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a3cb08",
   "metadata": {},
   "source": [
    "3. Загрузка исходного датасета\n",
    "\n",
    "- создаем папку data внутри проекта\n",
    "- скачиваем датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80dda658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  114M  100  114M    0     0  29.0M      0  0:00:03  0:00:03 --:--:-- 29.0M\n",
      "1600498 data/raw_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p data\n",
    "!curl -L https://code.s3.yandex.net/deep-learning/tweets.txt -o data/raw_dataset.csv\n",
    "!wc -l data/raw_dataset.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13964214",
   "metadata": {},
   "source": [
    "4. Подготовка данных\n",
    "\n",
    "Последовательно выполняется 3 этапа:\n",
    "\n",
    "1. Очистка текста (`preprocess_dataset`)\n",
    "   - удаление ссылок\n",
    "   - приведение к нижнему регистру\n",
    "   - удаление лишних символов\n",
    "\n",
    "2. Токенизация (`tokenize_dataset`)\n",
    "   - преобразование текста в `input_ids` с помощью токенизатора\n",
    "\n",
    "3. Разделение на выборки (`split_dataset`)\n",
    "   - 80% — train\n",
    "   - 10% — validation\n",
    "   - 10% — test\n",
    "\n",
    "В результате формируются CSV-файлы для обучения и оценки модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05c869c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    }
   ],
   "source": [
    "from src.data_utils import preprocess_dataset, tokenize_dataset, split_dataset\n",
    "\n",
    "preprocess_dataset(\"data/raw_dataset.csv\", \"data/dataset_processed.csv\")\n",
    "tokenize_dataset(\"data/dataset_processed.csv\", \"data/tokenized_dataset.csv\")\n",
    "split_dataset(\"data/tokenized_dataset.csv\", \"data/train.csv\", \"data/val.csv\", \"data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9826e6ae",
   "metadata": {},
   "source": [
    "5. Проверка доступности GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efd693f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU only\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344e3660",
   "metadata": {},
   "source": [
    "6. Обучения LSTM-модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b44b53f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Downloading builder script: 6.14kB [00:00, 14.2MB/s]                            \n",
      "Epoch 1/10 | Train Loss: 5.4619 | Val Loss: 5.1952 | Rouge1: 0.0999 | Rouge2: 0.0129\n",
      "Saved best model to models/lstm_next_token.pt\n",
      "Epoch 2/10 | Train Loss: 5.2314 | Val Loss: 5.1409 | Rouge1: 0.0915 | Rouge2: 0.0117\n",
      "Saved best model to models/lstm_next_token.pt\n",
      "Epoch 3/10 | Train Loss: 5.1798 | Val Loss: 5.1197 | Rouge1: 0.1012 | Rouge2: 0.0129\n",
      "Saved best model to models/lstm_next_token.pt\n",
      "Epoch 4/10 | Train Loss: 5.1535 | Val Loss: 5.1121 | Rouge1: 0.1032 | Rouge2: 0.0132\n",
      "Saved best model to models/lstm_next_token.pt\n",
      "Epoch 5/10 | Train Loss: 5.1367 | Val Loss: 5.1053 | Rouge1: 0.1045 | Rouge2: 0.0129\n",
      "Saved best model to models/lstm_next_token.pt\n",
      "Epoch 6/10 | Train Loss: 5.1259 | Val Loss: 5.1038 | Rouge1: 0.0641 | Rouge2: 0.0085\n",
      "Saved best model to models/lstm_next_token.pt\n",
      "Epoch 7/10 | Train Loss: 5.1151 | Val Loss: 5.0981 | Rouge1: 0.0754 | Rouge2: 0.0104\n",
      "Saved best model to models/lstm_next_token.pt\n",
      "Epoch 8/10 | Train Loss: 5.1076 | Val Loss: 5.0950 | Rouge1: 0.0731 | Rouge2: 0.0102\n",
      "Saved best model to models/lstm_next_token.pt\n",
      "Epoch 9/10 | Train Loss: 5.1027 | Val Loss: 5.0924 | Rouge1: 0.1029 | Rouge2: 0.0127\n",
      "Saved best model to models/lstm_next_token.pt\n",
      "Epoch 10/10 | Train Loss: 5.0961 | Val Loss: 5.0907 | Rouge1: 0.0837 | Rouge2: 0.0111\n",
      "Saved best model to models/lstm_next_token.pt\n",
      "Plot saved to models/loss_curves.png\n"
     ]
    }
   ],
   "source": [
    "!python -m src.lstm_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b02f5c2",
   "metadata": {},
   "source": [
    "7. Оценка LSTM-модели\n",
    "\n",
    "- вычисляется значение функции потерь\n",
    "- проводится генерация продолжений текста\n",
    "- рассчитываются метрики ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30af76cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Rouge: 100%|███████████████████████| 626/626 [05:45<00:00,  1.81it/s]\n",
      "Val Loss: 5.0881 | Rouge1: 0.0832 | Rouge2: 0.0113\n",
      "Examples:\n",
      "\n",
      "        Example 1\n",
      "Prompt:    armano became unemployed on may 11 took a little time off now looking for a job in bos or\n",
      "Reference: pdx and thats the story\n",
      "Generated: not\n",
      "\n",
      "\n",
      "        Example 2\n",
      "Prompt:    sad that the sun is\n",
      "Reference: gone\n",
      "Generated: over\n",
      "\n",
      "\n",
      "        Example 3\n",
      "Prompt:    yay thanks matcl\n",
      "Reference: ##ayton\n",
      "Generated: ##ub\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m src.eval_lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11de6059",
   "metadata": {},
   "source": [
    "8. Сравнение результатов с Transformer-моделью distilgpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e5518d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json: 100%|█████████████████████████████| 762/762 [00:00<00:00, 2.82MB/s]\n",
      "tokenizer_config.json: 100%|██████████████████| 26.0/26.0 [00:00<00:00, 104kB/s]\n",
      "vocab.json: 100%|██████████████████████████| 1.04M/1.04M [00:00<00:00, 3.83MB/s]\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "merges.txt: 100%|████████████████████████████| 456k/456k [00:00<00:00, 1.43MB/s]\n",
      "tokenizer.json: 100%|██████████████████████| 1.36M/1.36M [00:00<00:00, 11.3MB/s]\n",
      "model.safetensors: 100%|██████████████████████| 353M/353M [00:01<00:00, 177MB/s]\n",
      "Loading weights: 100%|█| 76/76 [00:00<00:00, 2090.34it/s, Materializing param=tr\n",
      "generation_config.json: 100%|███████████████████| 124/124 [00:00<00:00, 491kB/s]\n",
      "Filtering: 100%|█████████████████████| 160064/160064 [00:02<00:00, 67421.60it/s]\n",
      "Processing: 100%|█████████████████████| 160064/160064 [1:03:26<00:00, 42.05it/s]\n",
      "Rouge1: 0.0547 | Rouge2: 0.0051\n",
      "Examples:\n",
      "\n",
      "        Example 1\n",
      "Prompt:    armano became unemployed on may 11 took a little time off now looking for a job in bos\n",
      "Reference:  or pdx and thats the story\n",
      "Generated: om, but he is still in\n",
      "\n",
      "\n",
      "        Example 2\n",
      "Prompt:    sad that the sun\n",
      "Reference:  is gone\n",
      "Generated: 's rays\n",
      "\n",
      "\n",
      "        Example 3\n",
      "Prompt:    chaoticbullets mmhmnnn and you didnt make any\n",
      "Reference:  for me thanks grumbles\n",
      "Generated: errors.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m src.eval_transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06819cc6",
   "metadata": {},
   "source": [
    "ВЫВОД:\n",
    "\n",
    "По полученным метрикам ROUGE модель LSTM показывает лучшие результаты по сравнению с Transformer. Это означает, что её предсказания чаще совпадают с эталонными продолжениями текста.\n",
    "\n",
    "С учётом требований мобильных устройств (ограничения по памяти и скорости), LSTM является предпочтительным вариантом, чем трансформер из-за более простой архитектуры и меньшим вычислительным затратам.\n",
    "\n",
    "При этом примеры показывают, что предобученный Transformer (distilgpt2) генерирует более длинные и более логические продолжения. Однако его использование требует больше ресурсов. Потенциальное улучшение качества LSTM возможно за счёт увеличения объёма данных и более длительного обучения."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
